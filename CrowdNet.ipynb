{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7204a4d7",
   "metadata": {},
   "source": [
    "### Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import essential libraries for image processing, plotting, and handling data formats\n",
    "import cv2\n",
    "import scipy.io\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import h5py\n",
    "import glob\n",
    "import scipy.spatial\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import downscale_local_mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set up Caffe environment (update 'caffe_root' with your installation location)\n",
    "caffe_root = os.path.expanduser('~/deeplab-public-ver2/')\n",
    "sys.path.insert(0, os.path.join(caffe_root, 'python'))\n",
    "sys.path.insert(0, os.path.join(caffe_root, 'python/caffe/proto'))\n",
    "\n",
    "# Import Caffe modules for model operations\n",
    "import caffe\n",
    "import caffe_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35d709",
   "metadata": {},
   "source": [
    "### Constants Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the model, dataset, and weights\n",
    "model_name = 'CrowdNet'\n",
    "model_path = os.path.expanduser(os.path.join('models', model_name))  # Model definition path\n",
    "data_path = os.path.expanduser(os.path.join('~/data', model_name))   # Dataset location\n",
    "weights_path = os.path.expanduser(os.path.join('~/models', model_name))  # Pre-trained weights path\n",
    "\n",
    "# Dataset paths (can be expanded if multiple datasets are used)\n",
    "dataset_paths = ['dataset/UCF_CC_50']\n",
    "\n",
    "# Define slicing and patch dimensions for image processing\n",
    "slice_w = 256  # Width of each slice\n",
    "slice_h = 256  # Height of each slice\n",
    "\n",
    "patch_w = 225  # Width of each patch\n",
    "patch_h = 225  # Height of each patch\n",
    "\n",
    "# Define the network output size for density maps\n",
    "net_density_h = 28  # Height of the density map output\n",
    "net_density_w = 28  # Width of the density map output\n",
    "\n",
    "# GPU settings\n",
    "HAS_GPU = True  # Set to False if you want to use CPU\n",
    "GPU_ID = 0  # GPU ID to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b78b2",
   "metadata": {},
   "source": [
    "### VGG Mean Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03001b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mean values used for VGG input normalization\n",
    "VGG_ILSVRC_16_layers_mean = np.zeros((3, patch_h, patch_w), dtype='f4')\n",
    "\n",
    "# Assign RGB mean values (from ImageNet dataset)\n",
    "VGG_ILSVRC_16_layers_mean[0, :, :] = 103.939  # Mean for the blue channel\n",
    "VGG_ILSVRC_16_layers_mean[1, :, :] = 116.779  # Mean for the green channel\n",
    "VGG_ILSVRC_16_layers_mean[2, :, :] = 123.68   # Mean for the red channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18c2cc",
   "metadata": {},
   "source": [
    "### Load Ground Truth from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth from JSON file and populate a matrix (gt_matrix)\n",
    "def parse_gt_from_json(gt_json_file, matrix_shape):\n",
    "    gt_matrix = np.zeros(matrix_shape, dtype='uint8')  # Initialize the ground truth matrix\n",
    "    with open(gt_json_file, 'r') as json_file:\n",
    "        for idx, point in enumerate(json.load(json_file)):\n",
    "            try:\n",
    "                # Place 1 at the position defined by 'x' and 'y' in the ground truth\n",
    "                gt_matrix[int(math.floor(point['y'])), int(math.floor(point['x']))] = 1\n",
    "            except IndexError:\n",
    "                # Handle any indexing errors and print the problematic data point\n",
    "                print(gt_json_file, point['y'], point['x'], sys.exc_info())\n",
    "    return gt_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09faf274",
   "metadata": {},
   "source": [
    "### Gaussian Filter for Density Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian filter to generate density maps from ground truth points\n",
    "def gaussian_smooth_density(gt_list):\n",
    "    density_maps = []  # List to store generated density maps\n",
    "\n",
    "    # Iterate over each ground truth (gt) map\n",
    "    for gt_matrix in gt_list:\n",
    "        print(gt_matrix.shape)\n",
    "        density_map = np.zeros(gt_matrix.shape, dtype=np.float32)  # Initialize density map\n",
    "        non_zero_count = np.count_nonzero(gt_matrix)  # Count the number of non-zero points (people)\n",
    "\n",
    "        # If no points are present in the ground truth, return the empty density map\n",
    "        if non_zero_count == 0:\n",
    "            return density_map\n",
    "\n",
    "        # Get the (x, y) coordinates of the points in the ground truth\n",
    "        points = np.array(list(zip(np.nonzero(gt_matrix)[1], np.nonzero(gt_matrix)[0])))\n",
    "\n",
    "        # Build a KDTree for efficient nearest neighbor search\n",
    "        kd_tree = scipy.spatial.KDTree(points.copy(), leafsize=2048)\n",
    "\n",
    "        # Query the KDTree to find the distances to the nearest neighbors\n",
    "        distances, locations = kd_tree.query(points, k=2, eps=10.)\n",
    "\n",
    "        # Generate the density map using Gaussian filters\n",
    "        for idx, point in enumerate(points):\n",
    "            pt_2d = np.zeros(gt_matrix.shape, dtype=np.float32)\n",
    "            pt_2d[point[1], point[0]] = 1.  # Place a 1 at the location of the person\n",
    "\n",
    "            # Calculate the sigma for the Gaussian filter\n",
    "            if non_zero_count > 1:\n",
    "                sigma = distances[idx][1]  # Distance to the nearest neighbor\n",
    "            else:\n",
    "                sigma = np.average(np.array(gt_matrix.shape)) / 4.  # Default sigma for a single point\n",
    "\n",
    "            # Apply Gaussian filter to the point\n",
    "            density_map += scipy.ndimage.filters.gaussian_filter(pt_2d, sigma, mode='constant')\n",
    "\n",
    "        density_maps.append(density_map)  # Append the generated density map\n",
    "\n",
    "    return density_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141dfb78",
   "metadata": {},
   "source": [
    "### Load Images, Ground Truths, and Density Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6603ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images, ground truths, and density maps from the specified path\n",
    "def fetch_images_and_gts(path):\n",
    "    images = []  # Store loaded images\n",
    "    gts = []     # Store ground truth matrices\n",
    "    densities = []  # Store density maps\n",
    "\n",
    "    # Iterate over all ground truth files in the specified path\n",
    "    for gt_file in glob.glob(os.path.join(path, '*.json')):\n",
    "        print(gt_file)\n",
    "\n",
    "        # Load the corresponding image (either PNG or JPG)\n",
    "        if os.path.isfile(gt_file.replace('.json','.png')):\n",
    "            img = cv2.imread(gt_file.replace('.json','.png'))\n",
    "        else:\n",
    "            img = cv2.imread(gt_file.replace('.json','.jpg'))\n",
    "        images.append(img)\n",
    "        \n",
    "        # Load the ground truth using the previously defined function\n",
    "        gt = parse_gt_from_json(gt_file, img.shape[:-1])\n",
    "        gts.append(gt)\n",
    "        \n",
    "        # Load or generate the density map\n",
    "        density_file = gt_file.replace('.json','.h5')\n",
    "        if os.path.isfile(density_file):\n",
    "            # Load density map from file if it exists\n",
    "            with h5py.File(density_file, 'r') as hf:\n",
    "                density = np.array(hf.get('density'))\n",
    "        else:\n",
    "            # Generate the density map if not found and save it\n",
    "            density = gaussian_smooth_density([gt])[0]\n",
    "            with h5py.File(density_file, 'w') as hf:\n",
    "                hf['density'] = density\n",
    "        densities.append(density)\n",
    "\n",
    "    # Output the number of images and ground truth files loaded\n",
    "    print(path, len(images), 'loaded')\n",
    "    return (images, gts, densities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f75ab9a",
   "metadata": {},
   "source": [
    "### Density Resizing and Multiscale Pyramidal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the density map, scaling by factors scale_x and scale_y\n",
    "def resize_density_map(density_map, scale_x, scale_y):\n",
    "    return cv2.resize(density_map, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_CUBIC) / (scale_x * scale_y)\n",
    "\n",
    "# Apply multiscale pyramidal transformations to images and corresponding ground truths\n",
    "def apply_multiscale_transform(image_list, gt_list, scale_start=0.5, scale_end=1.3, scale_step=0.1):\n",
    "    scale_factors = np.arange(scale_start, scale_end, scale_step)  # Range of scale factors\n",
    "    multiscale_images = []  # To store scaled images\n",
    "    multiscale_gts = []     # To store scaled ground truths\n",
    "    \n",
    "    # For each image, apply scaling with the specified factors\n",
    "    for idx, img in enumerate(image_list):\n",
    "        for scale in scale_factors:\n",
    "            multiscale_images.append(cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC))\n",
    "            multiscale_gts.append(resize_density_map(gt_list[idx], fx=scale, fy=scale))\n",
    "    \n",
    "    return (multiscale_images, multiscale_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38ef92",
   "metadata": {},
   "source": [
    "### Image and Density Adaptation for Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5044c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt images and density maps to match the desired slicing dimensions\n",
    "def resize_images_and_densities(image_list, gt_list, slice_width=slice_w, slice_height=slice_h):\n",
    "    resized_images = []  # Store the resized images\n",
    "    resized_gts = []     # Store the resized ground truths\n",
    "    \n",
    "    # Adjust image and ground truth sizes for consistent slicing\n",
    "    for idx, image in enumerate(image_list):\n",
    "        img_height, img_width, _ = image.shape\n",
    "        num_slices_height = int(round(img_height / slice_height))\n",
    "        num_slices_width = int(round(img_width / slice_width))\n",
    "        \n",
    "        new_img_height = float(num_slices_height * slice_height)\n",
    "        new_img_width = float(num_slices_width * slice_width)\n",
    "        scale_x = new_img_width / img_width\n",
    "        scale_y = new_img_height / img_height\n",
    "        \n",
    "        # Resize the image and ensure it's aligned with the slicing grid\n",
    "        resized_images.append(cv2.resize(image, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_CUBIC))\n",
    "        assert resized_images[-1].shape[0] % slice_height == 0 and resized_images[-1].shape[1] % slice_width == 0\n",
    "        \n",
    "        # If ground truths are provided, resize them as well\n",
    "        if gt_list is not None:\n",
    "            resized_gts.append(resize_density_map(gt_list[idx], fx=scale_x, fy=scale_y))\n",
    "    \n",
    "    return (resized_images, resized_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472edcf1",
   "metadata": {},
   "source": [
    "### Generate Slices from Images and Ground Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08df791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate slices from images and ground truths\n",
    "def create_image_slices(image_list, gt_list, slice_width=slice_w, slice_height=slice_h, slice_offset=None):\n",
    "    if slice_offset is None:\n",
    "        slice_offset = slice_width  # Default offset is the width of a slice\n",
    "    \n",
    "    image_slices = []  # To store the sliced images\n",
    "    gt_slices = []     # To store the sliced ground truths\n",
    "    \n",
    "    # For each image, generate slices based on the specified slicing dimensions and offset\n",
    "    for idx, image in enumerate(image_list):\n",
    "        img_height, img_width, _ = image.shape\n",
    "        y_start, y_end = 0, slice_height\n",
    "        \n",
    "        # Loop over height\n",
    "        while y_end <= img_height:\n",
    "            x_start, x_end = 0, slice_width\n",
    "            \n",
    "            # Loop over width\n",
    "            while x_end <= img_width:\n",
    "                # Slice the image and append it\n",
    "                image_slices.append(image[y_start:y_end, x_start:x_end])\n",
    "                assert image_slices[-1].shape[:-1] == (slice_height, slice_width)\n",
    "                \n",
    "                # Slice the ground truth if provided\n",
    "                if gt_list is not None:\n",
    "                    gt_slices.append(gt_list[idx][y_start:y_end, x_start:x_end])\n",
    "                    assert gt_slices[-1].shape == (slice_height, slice_width)\n",
    "                \n",
    "                # Move to the next slice in width\n",
    "                x_start += slice_offset\n",
    "                x_end += slice_offset\n",
    "            \n",
    "            # Move to the next slice in height\n",
    "            y_start += slice_offset\n",
    "            y_end += slice_offset\n",
    "    \n",
    "    return (image_slices, gt_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f2b28",
   "metadata": {},
   "source": [
    "### Data Augmentation (Cropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data augmentation by cropping patches from images and ground truths\n",
    "def crop_image_patches(image_list, gt_list):\n",
    "    cropped_images = []  # Store cropped images\n",
    "    cropped_gts = []     # Store cropped ground truths\n",
    "    \n",
    "    # For each image, crop patches from different regions\n",
    "    for idx, image in enumerate(image_list):\n",
    "        img_height, img_width, _ = image.shape\n",
    "        gt_matrix = gt_list[idx]\n",
    "        \n",
    "        # Define positions to crop: top-left, top-right, bottom-left, bottom-right, and center patches\n",
    "        patch_positions = [\n",
    "            (0, 0),  # Top-left\n",
    "            (0, img_width - patch_w),  # Top-right\n",
    "            (img_height - patch_h, 0),  # Bottom-left\n",
    "            (img_height - patch_h, img_width - patch_w),  # Bottom-right\n",
    "            (int((img_height - patch_h) / 2), int((img_width - patch_w) / 2))  # Center\n",
    "        ]\n",
    "        \n",
    "        # Crop the image and ground truth at each position\n",
    "        for y_start, x_start in patch_positions:\n",
    "            y_end, x_end = y_start + patch_h, x_start + patch_w\n",
    "            cropped_images.append(image[y_start:y_end, x_start:x_end])\n",
    "            cropped_gts.append(gt_matrix[y_start:y_end, x_start:x_end])\n",
    "    \n",
    "    return (cropped_images, cropped_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7de07f",
   "metadata": {},
   "source": [
    "### Data Augmentation (Flipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e787338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data augmentation by flipping images and ground truths\n",
    "def flip_image_slices(image_list, gt_list):\n",
    "    flipped_images = []  # Store flipped images\n",
    "    flipped_gts = []     # Store flipped ground truths\n",
    "    \n",
    "    # For each image, add the original and the horizontally flipped version\n",
    "    for idx, image in enumerate(image_list):\n",
    "        gt_matrix = gt_list[idx]\n",
    "        \n",
    "        # Append original image and ground truth\n",
    "        flipped_images.append(image)\n",
    "        flipped_gts.append(gt_matrix)\n",
    "        \n",
    "        # Append horizontally flipped image and ground truth\n",
    "        flipped_images.append(np.fliplr(image))\n",
    "        flipped_gts.append(np.fliplr(gt_matrix))\n",
    "    \n",
    "    return (flipped_images, flipped_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93627a",
   "metadata": {},
   "source": [
    "### Shuffling Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f1bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle images and ground truths to randomize the order\n",
    "def shuffle_image_slices(image_list, gt_list):\n",
    "    shuffled_images = []  # Store shuffled images\n",
    "    shuffled_gts = []     # Store shuffled ground truths\n",
    "    \n",
    "    # Create a list of shuffled indices based on the number of images\n",
    "    shuffled_indices = list(range(len(image_list)))\n",
    "    shuffle(shuffled_indices)  # Shuffle the indices\n",
    "    \n",
    "    # Reorder images and ground truths according to the shuffled indices\n",
    "    for idx in shuffled_indices:\n",
    "        shuffled_images.append(image_list[idx])\n",
    "        shuffled_gts.append(gt_list[idx])\n",
    "    \n",
    "    return (shuffled_images, shuffled_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1a23d",
   "metadata": {},
   "source": [
    "### Sample Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and select samples based on density distribution (positive and negative samples)\n",
    "def select_samples_by_density(image_list, gt_list):\n",
    "    selected_images = []  # Store selected images\n",
    "    selected_gts = []     # Store selected ground truths\n",
    "    gt_counts = list(map(np.sum, gt_list))  # Compute sum of ground truths (i.e., crowd count)\n",
    "    max_count = max(gt_counts)  # Maximum count in the ground truths\n",
    "    \n",
    "    # Select positive samples (crowd density > 0)\n",
    "    for idx, image in enumerate(image_list):\n",
    "        if gt_counts[idx] >= 1 and random.random() < (gt_counts[idx]**2) / (max_count**2):\n",
    "            selected_images.append(image)\n",
    "            selected_gts.append(gt_list[idx])\n",
    "    \n",
    "    # Select negative samples (crowd density = 0)\n",
    "    negative_count = sum(count < 1 for count in gt_counts)\n",
    "    target_negative_count = len(selected_gts) // 6  # Target for negative samples\n",
    "    negative_keep_prob = min(1., float(target_negative_count) / float(negative_count))\n",
    "    \n",
    "    # Append negative samples based on the probability\n",
    "    for idx, image in enumerate(image_list):\n",
    "        if gt_counts[idx] < 1 and random.random() < negative_keep_prob:\n",
    "            selected_images.append(image)\n",
    "            selected_gts.append(gt_list[idx])\n",
    "    \n",
    "    return (selected_images, selected_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5832d",
   "metadata": {},
   "source": [
    "### Positive Image and Ground Truth Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68873dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for storing images and their corresponding density maps\n",
    "image_data = []  # List to store images\n",
    "density_data = []  # List to store density maps\n",
    "\n",
    "# Loop through each dataset path and load the images, ground truths, and densities\n",
    "for dataset_path in dataset_paths:\n",
    "    images, ground_truths, densities = fetch_images_and_gts(dataset_path)  # Load images and density maps for each path\n",
    "    image_data += images  # Append the loaded images to the list\n",
    "    density_data += densities  # Append the corresponding density maps to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9914234",
   "metadata": {},
   "source": [
    "### Split Dataset into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset: 80% for training, 20% for testing\n",
    "image_data_train, image_data_test, density_data_train, density_data_test = train_test_split(\n",
    "    image_data, density_data, test_size=0.2  # Reserve 20% of data for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa4b6a",
   "metadata": {},
   "source": [
    "### Data Augmentation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_slice_data(images, densities, is_train=True):\n",
    "    \"\"\"Applies multiscale pyramidal transformations, generates slices, flips, corrects sample distributions,\n",
    "    and shuffles the data. If `is_train` is True, it adjusts accordingly.\"\"\"\n",
    "    \n",
    "    # Apply multiscale pyramidal transformations\n",
    "    print(f'\\nMultiscale pyramidal - {\"TRAIN\" if is_train else \"TEST\"}:')\n",
    "    images, densities = apply_multiscale_transform(images, densities)\n",
    "    print(f'After multiscale pyramidal: {len(images)} images, {len(densities)} density maps')\n",
    "    \n",
    "    # Generate patches (slices) from the images and ground truths\n",
    "    print('\\nGenerate slices:')\n",
    "    images, densities = create_image_slices(images, densities, slice_w=patch_w, slice_h=patch_h, offset=8 if is_train else None)\n",
    "    print(f'After generating slices: {len(images)} images, {len(densities)} density maps')\n",
    "    \n",
    "    # Apply horizontal flip augmentation\n",
    "    print('\\nApply horizontal flip:')\n",
    "    images, densities = flip_image_slices(images, densities)\n",
    "    print(f'After flipping: {len(images)} images, {len(densities)} density maps')\n",
    "    \n",
    "    # If it's training data, correct the sample distribution\n",
    "    if is_train:\n",
    "        print('\\nCorrect sample distribution (train):')\n",
    "        images, densities = select_samples_by_density(images, densities)\n",
    "        print(f'After sample distribution correction: {len(images)} images, {len(densities)} density maps')\n",
    "    \n",
    "    # Shuffle the data to randomize the order\n",
    "    print('\\nShuffle data:')\n",
    "    images, densities = shuffle_image_slices(images, densities)\n",
    "    print(f'After shuffling: {len(images)} images, {len(densities)} density maps')\n",
    "    \n",
    "    return images, densities\n",
    "\n",
    "# Apply data augmentation and preprocessing for both train and test sets\n",
    "image_train, density_train = augment_and_slice_data(image_data_train, density_data_train, is_train=True)\n",
    "image_test, density_test = augment_and_slice_data(image_data_test, density_data_test, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff852d36",
   "metadata": {},
   "source": [
    "### Plot Distribution of TRAIN Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of density values for each sample in the training set\n",
    "train_density_sums = [np.sum(density_map) for density_map in density_train]\n",
    "\n",
    "# Sort the sums for better visualization\n",
    "train_density_sums.sort()\n",
    "\n",
    "# Plot the sorted sums\n",
    "plt.plot(train_density_sums)\n",
    "plt.title('Distribution of TRAIN Sample Density Sums')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Sum of Densities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e869ed6",
   "metadata": {},
   "source": [
    "### Write Data to HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf14452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data and save it in HDF5 format\n",
    "def process_and_export_hdf5(image_list, density_list, save_path, phase, mean_values):\n",
    "    # Ensure the target path exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    batch_size = 7000  # Set batch size to avoid hitting HDF5 file size limits\n",
    "    \n",
    "    # Initialize arrays for processing images and labels in batches\n",
    "    image_batch = np.zeros((batch_size, 3, patch_h, patch_w), dtype=np.float32)  # Image batch\n",
    "    density_batch = np.zeros((batch_size, net_density_h, net_density_w), dtype=np.float32)  # Density map batch\n",
    "    \n",
    "    # Open a text file to store the names of the generated HDF5 files\n",
    "    with open(os.path.join(save_path, phase + '.txt'), 'w') as file_log:\n",
    "        batch_start = 0  # Start index for batch processing\n",
    "        \n",
    "        while batch_start < len(image_list):\n",
    "            # Determine the end index for the current batch\n",
    "            batch_end = min(batch_start + batch_size, len(image_list))\n",
    "            \n",
    "            print(f'{batch_start} - {batch_end - 1} / {len(image_list)}')  # Print progress\n",
    "\n",
    "            # Create an HDF5 file to store the current batch\n",
    "            hdf5_filename = os.path.join(save_path, f'{phase}_{batch_start}.h5')\n",
    "            with h5py.File(hdf5_filename, 'w') as hf:\n",
    "                # Process the current batch\n",
    "                for idx, image in enumerate(image_list[batch_start:batch_end]):\n",
    "                    # Transpose the image and subtract the mean\n",
    "                    image_batch[idx] = image.copy().transpose(2, 0, 1).astype(np.float32) - mean_values\n",
    "                    # Resize the corresponding density map and store it\n",
    "                    density_batch[idx] = resize_density_map(\n",
    "                        density_list[batch_start + idx],\n",
    "                        fx=float(net_density_w) / patch_w,\n",
    "                        fy=float(net_density_h) / patch_h\n",
    "                    )\n",
    "                # Write the processed batch to the HDF5 file\n",
    "                hf['data'] = image_batch[:(batch_end - batch_start)]\n",
    "                hf['label'] = density_batch[:(batch_end - batch_start)]\n",
    "            \n",
    "            # Log the HDF5 file name in the text file\n",
    "            file_log.write(hdf5_filename + '\\n')\n",
    "\n",
    "            # Move to the next batch\n",
    "            batch_start += batch_size\n",
    "\n",
    "# Train set processing\n",
    "print('TRAIN:')\n",
    "process_and_export_hdf5(image_train, density_train, data_path, 'train', VGG_ILSVRC_16_layers_mean)\n",
    "\n",
    "# Test set processing\n",
    "print('TEST:')\n",
    "process_and_export_hdf5(image_test, density_test, data_path, 'test', VGG_ILSVRC_16_layers_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80016bdc",
   "metadata": {},
   "source": [
    "### Caffe Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586526cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Caffe's command-line interface to start training the model.\n",
    "# The specified solver configuration and pre-trained weights are provided.\n",
    "\n",
    "# Run the Caffe training command using the solver and pre-trained weights.\n",
    "# This command assumes that the Caffe framework is installed and configured properly.\n",
    "!caffe train \\\n",
    "    -solver models/CrowdNet/solver.prototxt \\\n",
    "    -weights weights/VGG_ILSVRC_16_layers/VGG_ILSVRC_16_layers.caffemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e26e6",
   "metadata": {},
   "source": [
    "### Image Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a single image: subtract the mean and transpose dimensions\n",
    "def process_single_image(image, mean_values):\n",
    "    \"\"\"\n",
    "    Process a single image by transposing it from (H, W, C) to (C, H, W) \n",
    "    and subtracting the mean values for normalization.\n",
    "    \"\"\"\n",
    "    processed_image = image.copy()  # Create a copy to avoid modifying the original\n",
    "    processed_image = processed_image.transpose(2, 0, 1).astype(np.float32)  # Transpose (H, W, C) -> (C, H, W)\n",
    "    processed_image -= mean_values  # Subtract the mean values for normalization\n",
    "    return processed_image\n",
    "\n",
    "# Process a batch of images: apply image processing to each image in the batch\n",
    "def process_image_batch(image_list, mean_values):\n",
    "    \"\"\"\n",
    "    Process a batch of images by applying the image_process function to each image.\n",
    "    The batch will have the shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    # Initialize an empty batch with the appropriate shape (batch_size, channels, height, width)\n",
    "    batch = np.zeros((len(image_list),) + image_list[0].transpose(2, 0, 1).shape, dtype=np.float32)\n",
    "    \n",
    "    # Process each image in the batch\n",
    "    for idx, image in enumerate(image_list):\n",
    "        batch[idx] = process_single_image(image, mean_values)\n",
    "    \n",
    "    return batch  # Return the processed batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc63d5",
   "metadata": {},
   "source": [
    "### Prediction with Caffe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions using the Caffe model on a batch of images\n",
    "def predict(image_list, mean_values):\n",
    "    \"\"\"\n",
    "    Perform predictions on a list of images using the Caffe model.\n",
    "    The output is a list of predicted density maps.\n",
    "    \"\"\"\n",
    "    predictions = []  # To store predicted outputs (density maps)\n",
    "\n",
    "    # Iterate over each image in the input dataset\n",
    "    for idx, image in enumerate(image_list):\n",
    "        # Adapt the image to match the network's required input dimensions\n",
    "        adapted_image, _ = resize_images_and_densities([image], None, slice_w=patch_w, slice_h=patch_h)\n",
    "        \n",
    "        # Generate patches (slices) from the adapted image\n",
    "        image_slices, _ = create_image_slices(adapted_image, None, slice_w=patch_w, slice_h=patch_h, offset=None)\n",
    "        \n",
    "        # Define the layer from which to extract the output\n",
    "        output_layer = 'conv6'  # Use the output from the 'conv6' layer\n",
    "        batch_size = 10  # Process images in batches of 10\n",
    "        \n",
    "        image_predictions = []  # Store predictions for the current image\n",
    "        batch_start = 0  # Start index for batch processing\n",
    "        \n",
    "        # Process the image slices in batches\n",
    "        while batch_start < len(image_slices):\n",
    "            # Define the end index for the current batch\n",
    "            batch_end = min(batch_start + batch_size, len(image_slices))\n",
    "            \n",
    "            # Process the batch of images (subtract mean, reshape, etc.)\n",
    "            batch = process_image_batch(image_slices[batch_start:batch_end], mean_values)\n",
    "            net.blobs['data'].reshape(batch.shape[0], batch.shape[1], batch.shape[2], batch.shape[3])  # Reshape network input\n",
    "            net.blobs['data'].data[...] = batch  # Set network input with the processed batch\n",
    "            \n",
    "            # Perform forward pass through the network\n",
    "            net.forward()\n",
    "            \n",
    "            # Extract predictions from the specified output layer\n",
    "            for output in net.blobs[output_layer].data:\n",
    "                predicted_density = output[0]  # Extract the single-channel output\n",
    "                image_predictions.append(predicted_density)\n",
    "            \n",
    "            # Move to the next batch\n",
    "            batch_start += batch_size\n",
    "        \n",
    "        # Store the predictions for the current image\n",
    "        predictions.append(image_predictions)\n",
    "    \n",
    "    return predictions  # Return predictions for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a058ca4",
   "metadata": {},
   "source": [
    "### Model Evaluation and Prediction with Caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbff5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model definition file (deploy configuration)\n",
    "model_definition = os.path.join(model_path, 'deploy.prototxt')\n",
    "\n",
    "# Loop through each set of model weights (.caffemodel) in the weights directory\n",
    "for weights_file in glob.glob(os.path.join(weights_path, '*.caffemodel')):\n",
    "    # Load the network with the model definition and corresponding weights\n",
    "    net = caffe.Net(model_definition, weights_file, caffe.TEST)\n",
    "    \n",
    "    # Set the computation mode to GPU or CPU based on availability\n",
    "    if HAS_GPU:\n",
    "        caffe.set_device(GPU_ID)\n",
    "        caffe.set_mode_gpu()\n",
    "    else:\n",
    "        caffe.set_mode_cpu()\n",
    "    \n",
    "    # Start the timer to measure the prediction time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform predictions on the test set\n",
    "    predictions = predict(image_test, VGG_ILSVRC_16_layers_mean)\n",
    "    \n",
    "    # Print the time taken for predictions\n",
    "    print('Prediction time:', time.time() - start_time)\n",
    "    \n",
    "    # Calculate the sum of density maps for the test set (ground truth and predictions)\n",
    "    ground_truth_counts = np.array(list(map(np.sum, density_test)))  # Ground truth counts\n",
    "    predicted_counts = np.array(list(map(np.sum, predictions)))  # Predicted counts\n",
    "\n",
    "    # Calculate and print the Mean Absolute Error (MAE) for the current model weights\n",
    "    mae = np.average(np.abs(predicted_counts - ground_truth_counts))\n",
    "    print(f'{weights_file} MAE: {mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
